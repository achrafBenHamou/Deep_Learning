{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Data Description ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\".//Data//train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\".//Data//test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3534 entries, 0 to 3533\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   textID     3534 non-null   object\n",
      " 1   text       3534 non-null   object\n",
      " 2   sentiment  3534 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 83.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  selected_text\n",
       "0  f87dea47db            NaN\n",
       "1  96d74cb729            NaN\n",
       "2  eee518ae67            NaN\n",
       "3  01082688c6            NaN\n",
       "4  33987a8ee5            NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\".//Data//sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      I`d have responded, if I were going\n",
       "1            Sooo SAD I will miss you here in San Diego!!!\n",
       "2                                my boss is bullying me...\n",
       "3                           what interview! leave me alone\n",
       "4         Sons of ****, why couldn`t they put them on t...\n",
       "                               ...                        \n",
       "27476     wish we could come see u on Denver  husband l...\n",
       "27477     I`ve wondered about rake to.  The client has ...\n",
       "27478     Yay good for both of you. Enjoy the break - y...\n",
       "27479                           But it was worth it  ****.\n",
       "27480       All this flirting going on - The ATG smiles...\n",
       "Name: text, Length: 27481, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb  \n",
    "%matplotlib inline  \n",
    "sb.countplot(x='sentiment', data = train_df, palette = 'hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb  \n",
    "%matplotlib inline  \n",
    "sb.countplot(x='sentiment', data = test_df, palette = 'hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## Data Preprocessing ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'have', 'responded', 'if', 'i', 'were', 'going'], ['sooo', 'sad']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "def tweet_preprocessing(tweets):\n",
    "   list_tweets_words=[]\n",
    "   for tweet in tweets:\n",
    "    list_tweet_words=[]\n",
    "    tweet=tweet.lower()\n",
    "    ##Remove userName\n",
    "    tweet=re.sub(r\"@[a-z0-9_-]*\",\"\",tweet)\n",
    "    ##Remove hyperlinks\n",
    "    tweet=re.sub(r\"https?://.*[\\s]*\",\"\",tweet)\n",
    "    ## Remove numbers and characters\n",
    "    tweet=re.sub(r\"[^a-z ]*\",\"\",tweet)\n",
    "    ## Replace multiple spaces by single space\n",
    "    tweet=re.sub(r\"[\\s]+\",\" \",tweet)\n",
    "    ##Word Tokenization\n",
    "    tweet_words=word_tokenize(tweet)\n",
    "    for word in tweet_words:\n",
    "        #if(word not in stop_words):\n",
    "         # word=stemmer.stem(word)\n",
    "          list_tweet_words.append(word)\n",
    "    ## join : from list of words to string\n",
    "    list_tweets_words.append(list_tweet_words)\n",
    "   return list_tweets_words\n",
    "\n",
    "tweets =['99I`d have responded, if I were going','Sooo SAD']  \n",
    "test = tweet_preprocessing(tweets)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>selected_text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, of]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \\\n",
       "0  I`d have responded, if I were going   neutral   \n",
       "1                             Sooo SAD  negative   \n",
       "2                          bullying me  negative   \n",
       "3                       leave me alone  negative   \n",
       "4                        Sons of ****,  negative   \n",
       "\n",
       "                                       text_tokenize  \\\n",
       "0          [id, have, responded, if, i, were, going]   \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2                       [my, boss, is, bullying, me]   \n",
       "3                [what, interview, leave, me, alone]   \n",
       "4  [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "\n",
       "                      selected_text_tokenize  \n",
       "0  [id, have, responded, if, i, were, going]  \n",
       "1                                [sooo, sad]  \n",
       "2                             [bullying, me]  \n",
       "3                         [leave, me, alone]  \n",
       "4                                 [sons, of]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add 2 new columns to our dataframe content listes of splitted text end selected text\n",
    "train_df[\"text_tokenize\"]=tweet_preprocessing(train_df.text.astype(str))\n",
    "train_df[\"selected_text_tokenize\"]=tweet_preprocessing(train_df.selected_text.astype(str))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save the new dataframe in other file csv\n",
    "#train_df.to_csv(\"preprocessed_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>selected_text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "\n",
       "                                       selected_text sentiment  \\\n",
       "0                I`d have responded, if I were going   neutral   \n",
       "1                                           Sooo SAD  negative   \n",
       "2                                        bullying me  negative   \n",
       "3                                     leave me alone  negative   \n",
       "4                                      Sons of ****,  negative   \n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral   \n",
       "\n",
       "                                       text_tokenize  \\\n",
       "0          [id, have, responded, if, i, were, going]   \n",
       "1  [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2                       [my, boss, is, bullying, me]   \n",
       "3                [what, interview, leave, me, alone]   \n",
       "4  [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "5                                                 []   \n",
       "\n",
       "                      selected_text_tokenize  \n",
       "0  [id, have, responded, if, i, were, going]  \n",
       "1                                [sooo, sad]  \n",
       "2                             [bullying, me]  \n",
       "3                         [leave, me, alone]  \n",
       "4                                 [sons, of]  \n",
       "5                                         []  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessed_df = pd.read_csv(\"preprocessed_train_data.csv\",keep_default_na=False)\n",
    "#del preprocessed_df['Unnamed: 0']\n",
    "preprocessed_df = train_df\n",
    "preprocessed_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>selected_text_tokenize</th>\n",
       "      <th>first_index</th>\n",
       "      <th>last_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, of]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, we, could, come, see, u, on, denver, hu...</td>\n",
       "      <td>[d, lost]</td>\n",
       "      <td>nan</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ive, wondered, about, rake, to, the, client, ...</td>\n",
       "      <td>[dont, force]</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, for, both, of, you, enjoy, the, br...</td>\n",
       "      <td>[yay, good, for, both, of, you]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0              [id, have, responded, if, i, were, going]   \n",
       "1      [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2                           [my, boss, is, bullying, me]   \n",
       "3                    [what, interview, leave, me, alone]   \n",
       "4      [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "...                                                  ...   \n",
       "27476  [wish, we, could, come, see, u, on, denver, hu...   \n",
       "27477  [ive, wondered, about, rake, to, the, client, ...   \n",
       "27478  [yay, good, for, both, of, you, enjoy, the, br...   \n",
       "27479                          [but, it, was, worth, it]   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...   \n",
       "\n",
       "                                  selected_text_tokenize  first_index  \\\n",
       "0              [id, have, responded, if, i, were, going]            0   \n",
       "1                                            [sooo, sad]            0   \n",
       "2                                         [bullying, me]            3   \n",
       "3                                     [leave, me, alone]            2   \n",
       "4                                             [sons, of]            0   \n",
       "...                                                  ...          ...   \n",
       "27476                                          [d, lost]          nan   \n",
       "27477                                      [dont, force]           13   \n",
       "27478                    [yay, good, for, both, of, you]            0   \n",
       "27479                          [but, it, was, worth, it]            0   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...            0   \n",
       "\n",
       "       last_index  \n",
       "0               6  \n",
       "1               1  \n",
       "2               4  \n",
       "3               4  \n",
       "4               1  \n",
       "...           ...  \n",
       "27476           9  \n",
       "27477          14  \n",
       "27478           5  \n",
       "27479           1  \n",
       "27480           9  \n",
       "\n",
       "[27481 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "# if we want first index we choose True, and False for the latest index\n",
    "# we should use the next 2 lines one time (transform text to list)\n",
    "#preprocessed_df[\"text_tokenize\"] = preprocessed_df.text_tokenize.apply(lambda x: ast.literal_eval(x))\n",
    "#preprocessed_df[\"selected_text_tokenize\"] = preprocessed_df.selected_text_tokenize.apply(lambda x: ast.literal_eval(x))\n",
    "#preprocessed_df.head()\n",
    "\n",
    "def find_index (text_list,selectedText_list,i=True):  \n",
    "    #find first word in selected_text\n",
    "    try :\n",
    "        if i == True :\n",
    "            first_w = selectedText_list[0]\n",
    "            #print(first_w)\n",
    "            return (int(text_list.index(first_w))) \n",
    "            #find last word in selected_text\n",
    "        else:\n",
    "            last_w = selectedText_list[-1]\n",
    "            # look for first_w index in text list\n",
    "            return (int(text_list.index(last_w)))\n",
    "    except :\n",
    "        pass\n",
    "a = preprocessed_df.text_tokenize.loc[2]\n",
    "b = preprocessed_df.selected_text_tokenize.loc[2]  \n",
    "s = find_index (a,b,i=True)\n",
    "s\n",
    "\n",
    "preprocessed_df[\"first_index\"] = preprocessed_df.apply(lambda row : find_index(row.text_tokenize,row.selected_text_tokenize,True),axis=1)\n",
    "preprocessed_df[\"last_index\"] = preprocessed_df.apply(lambda row : find_index(row.text_tokenize,row.selected_text_tokenize,False),axis=1)\n",
    "#to convert float to int pandas\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "preprocessed_df['first_index'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "preprocessed_df['last_index'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "######## tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>selected_text_tokenize</th>\n",
       "      <th>first_index</th>\n",
       "      <th>last_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, of]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, we, could, come, see, u, on, denver, hu...</td>\n",
       "      <td>[d, lost]</td>\n",
       "      <td>nan</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ive, wondered, about, rake, to, the, client, ...</td>\n",
       "      <td>[dont, force]</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, for, both, of, you, enjoy, the, br...</td>\n",
       "      <td>[yay, good, for, both, of, you]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0              [id, have, responded, if, i, were, going]   \n",
       "1      [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2                           [my, boss, is, bullying, me]   \n",
       "3                    [what, interview, leave, me, alone]   \n",
       "4      [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "...                                                  ...   \n",
       "27476  [wish, we, could, come, see, u, on, denver, hu...   \n",
       "27477  [ive, wondered, about, rake, to, the, client, ...   \n",
       "27478  [yay, good, for, both, of, you, enjoy, the, br...   \n",
       "27479                          [but, it, was, worth, it]   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...   \n",
       "\n",
       "                                  selected_text_tokenize  first_index  \\\n",
       "0              [id, have, responded, if, i, were, going]            0   \n",
       "1                                            [sooo, sad]            0   \n",
       "2                                         [bullying, me]            3   \n",
       "3                                     [leave, me, alone]            2   \n",
       "4                                             [sons, of]            0   \n",
       "...                                                  ...          ...   \n",
       "27476                                          [d, lost]          nan   \n",
       "27477                                      [dont, force]           13   \n",
       "27478                    [yay, good, for, both, of, you]            0   \n",
       "27479                          [but, it, was, worth, it]            0   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...            0   \n",
       "\n",
       "       last_index  \n",
       "0               6  \n",
       "1               1  \n",
       "2               4  \n",
       "3               4  \n",
       "4               1  \n",
       "...           ...  \n",
       "27476           9  \n",
       "27477          14  \n",
       "27478           5  \n",
       "27479           1  \n",
       "27480           9  \n",
       "\n",
       "[27481 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd \n",
    "import ast\n",
    "import tensorflow\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26477"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tokenize and make the index of words\n",
    "tokenizer = Tokenizer(num_words=20000,oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df.text_tokenize)\n",
    "tokenized_text = tokenizer.texts_to_sequences(df.text_tokenize)\n",
    "tokenized_selected_text = tokenizer.texts_to_sequences(df.selected_text_tokenize)\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index of word but\n",
    "tokenizer.word_index[\"but\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 291,   16, 9941, ...,    0,    0,    0],\n",
       "       [ 410,  116,    1, ...,    0,    0,    0],\n",
       "       [   5, 1266,    9, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 220,   29,   11, ...,    0,    0,    0],\n",
       "       [  19,    8,   27, ...,    0,    0,    0],\n",
       "       [  28,   31, 6007, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after tokenzation we can prepare input of the module  \n",
    "pad_token_text = pad_sequences(tokenized_text,padding = \"post\")\n",
    "pad_token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pad_token_text).to_csv(\"pad_token_text.csv\",header=None,index=None)\n",
    "df.to_csv(\"tokenized.csv\",index=None)\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "## and finally -----> the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.python.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_index</th>\n",
       "      <th>last_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_index  last_index\n",
       "0            0           6\n",
       "1            0           1\n",
       "2            3           4\n",
       "3            2           4\n",
       "4            0           1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = df[[\"first_index\",\"last_index\"]]\n",
    "targets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>291</td>\n",
       "      <td>16</td>\n",
       "      <td>9941</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>1425</td>\n",
       "      <td>2162</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1266</td>\n",
       "      <td>9</td>\n",
       "      <td>9942</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>1099</td>\n",
       "      <td>342</td>\n",
       "      <td>15</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2679</td>\n",
       "      <td>12</td>\n",
       "      <td>109</td>\n",
       "      <td>388</td>\n",
       "      <td>86</td>\n",
       "      <td>314</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>6750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3    4    5    6   7     8     9   ...  23  24  25  26  \\\n",
       "0   291    16  9941    68    1  119   45   0     0     0  ...   0   0   0   0   \n",
       "1   410   116     1    59   90    7   87  10  1425  2162  ...   0   0   0   0   \n",
       "2     5  1266     9  9942   15    0    0   0     0     0  ...   0   0   0   0   \n",
       "3    57  1099   342    15  490    0    0   0     0     0  ...   0   0   0   0   \n",
       "4  2679    12   109   388   86  314  128  14     3  6750  ...   0   0   0   0   \n",
       "\n",
       "   27  28  29  30  31  32  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv(\"pad_token_text.csv\",header= None)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after preparing input and output we can split data for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(training.values, targets.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_model(vocab_size):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, 128, input_length=33),\n",
    "        Bidirectional(GRU(128, return_sequences=True, dropout=0.8, recurrent_dropout=0.8)),\n",
    "        Bidirectional(GRU(128,return_sequences=True, dropout=0.8, recurrent_dropout=0.8)),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='elu',kernel_regularizer=l1_l2()),\n",
    "        Dropout(0.8),\n",
    "        Dense(2, activation='elu'),\n",
    "        Flatten(),\n",
    "        Dense(2, activation='elu')\n",
    "\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21984, 33)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21984, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 33, 128)           2816000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 33, 256)           197376    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 33, 256)           295680    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 33, 256)           1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 33, 64)            16448     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 33, 2)             130       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 66)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 134       \n",
      "=================================================================\n",
      "Total params: 3,326,792\n",
      "Trainable params: 3,326,280\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab = 22000\n",
    "model = first_model(vocab)\n",
    "es = EarlyStopping(patience=5)\n",
    "#tweet_sentiment.hdf5\n",
    "mcp_save = ModelCheckpoint('model.hdf5', save_best_only=True, monitor='val_mse')\n",
    "model.compile(loss=\"mse\",optimizer=\"adam\",metrics=['mse',\"mae\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17587 samples, validate on 4397 samples\n",
      "Epoch 1/100\n",
      "  640/17587 [>.............................] - ETA: 4:47 - loss: nan - mean_squared_error: nan - mean_absolute_error: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-e31e5e629c94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# epochs 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweet_sentiment1.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1214\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    243\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2822\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2823\u001b[0m     updated = session.run(\n\u001b[1;32m-> 2824\u001b[1;33m         fetches=fetches, feed_dict=feed_dict, **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2825\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# epochs 100   \n",
    "history = model.fit(x=x_train, y=y_train, batch_size = 32, epochs=100, validation_split = 0.2,callbacks=[es,mcp_save])\n",
    "model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
