{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "## Data Description ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\".//Data//train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\".//Data//test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3534 entries, 0 to 3533\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   textID     3534 non-null   object\n",
      " 1   text       3534 non-null   object\n",
      " 2   sentiment  3534 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 83.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  selected_text\n",
       "0  f87dea47db            NaN\n",
       "1  96d74cb729            NaN\n",
       "2  eee518ae67            NaN\n",
       "3  01082688c6            NaN\n",
       "4  33987a8ee5            NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\".//Data//sample_submission.csv\")\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      I`d have responded, if I were going\n",
       "1            Sooo SAD I will miss you here in San Diego!!!\n",
       "2                                my boss is bullying me...\n",
       "3                           what interview! leave me alone\n",
       "4         Sons of ****, why couldn`t they put them on t...\n",
       "                               ...                        \n",
       "27476     wish we could come see u on Denver  husband l...\n",
       "27477     I`ve wondered about rake to.  The client has ...\n",
       "27478     Yay good for both of you. Enjoy the break - y...\n",
       "27479                           But it was worth it  ****.\n",
       "27480       All this flirting going on - The ATG smiles...\n",
       "Name: text, Length: 27481, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb  \n",
    "%matplotlib inline  \n",
    "sb.countplot(x='sentiment', data = train_df, palette = 'hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb  \n",
    "%matplotlib inline  \n",
    "sb.countplot(x='sentiment', data = test_df, palette = 'hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## Data Preprocessing ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['99id', 'have', 'responded', 'if', 'were', 'going'], ['sooo', 'sad']]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "stemmer=PorterStemmer()\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "def tweet_preprocessing(tweets):\n",
    "   list_tweets_words=[]\n",
    "   for tweet in tweets:\n",
    "    list_tweet_words=[]\n",
    "    tweet = tweet.replace('.', ' ')\n",
    "    tweet = tweet.replace(',', '')\n",
    "    tweet = tweet.replace(\"`\", \"\")\n",
    "    tweet = tweet.replace(\"'\", \"\")\n",
    "    tweet=tweet.lower()\n",
    "    ##Remove userName\n",
    "    #tweet=re.sub(r\"@[a-z0-9_-]*\",\"\",tweet)\n",
    "    ##Remove hyperlinks\n",
    "    #tweet=re.sub(r\"https?://.*[\\s]*\",\"\",tweet)\n",
    "    ## Remove numbers and characters\n",
    "    #tweet=re.sub(r\"[^a-z ]*\",\"\",tweet)\n",
    "    ## Replace multiple spaces by single space\n",
    "    tweet=re.sub(r\"[\\s]+\",\" \",tweet)\n",
    "    ##Word Tokenization\n",
    "    tweet_words=word_tokenize(tweet)\n",
    "    for word in tweet_words:\n",
    "        if len(word) > 1:\n",
    "        #if(word not in stop_words):\n",
    "         # word=stemmer.stem(word)\n",
    "            list_tweet_words.append(word)\n",
    "    ## join : from list of words to string\n",
    "    list_tweets_words.append(list_tweet_words)\n",
    "   return list_tweets_words\n",
    "\n",
    "tweets =['99I`d have responded, if I were going','Sooo SAD']  \n",
    "test = tweet_preprocessing(tweets)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>selected_text_tokenize</th>\n",
       "      <th>first_index</th>\n",
       "      <th>last_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, have, responded, if, were, going]</td>\n",
       "      <td>[id, have, responded, if, were, going]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, will, miss, you, here, in, san, di...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, of]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[http, //www, dothebouncy, com/smf, some, sham...</td>\n",
       "      <td>[http, //www, dothebouncy, com/smf, some, sham...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "      <td>[2am, feedings, for, the, baby, are, fun, when...</td>\n",
       "      <td>[fun]</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>[soooo, high]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>[both, of, you]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[journey, wow, just, became, cooler, hehe, is,...</td>\n",
       "      <td>[wow, just, became, cooler]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6  6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7  50e14c0bb8                                         Soooo high   \n",
       "8  e050245fbd                                        Both of you   \n",
       "9  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "\n",
       "                                       selected_text sentiment  \\\n",
       "0                I`d have responded, if I were going   neutral   \n",
       "1                                           Sooo SAD  negative   \n",
       "2                                        bullying me  negative   \n",
       "3                                     leave me alone  negative   \n",
       "4                                      Sons of ****,  negative   \n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral   \n",
       "6                                                fun  positive   \n",
       "7                                         Soooo high   neutral   \n",
       "8                                        Both of you   neutral   \n",
       "9                       Wow... u just became cooler.  positive   \n",
       "\n",
       "                                       text_tokenize  \\\n",
       "0             [id, have, responded, if, were, going]   \n",
       "1  [sooo, sad, will, miss, you, here, in, san, di...   \n",
       "2                       [my, boss, is, bullying, me]   \n",
       "3                [what, interview, leave, me, alone]   \n",
       "4  [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "5  [http, //www, dothebouncy, com/smf, some, sham...   \n",
       "6  [2am, feedings, for, the, baby, are, fun, when...   \n",
       "7                                      [soooo, high]   \n",
       "8                                    [both, of, you]   \n",
       "9  [journey, wow, just, became, cooler, hehe, is,...   \n",
       "\n",
       "                              selected_text_tokenize  first_index  last_index  \n",
       "0             [id, have, responded, if, were, going]            0           4  \n",
       "1                                        [sooo, sad]            0           1  \n",
       "2                                     [bullying, me]            3           4  \n",
       "3                                 [leave, me, alone]            2           4  \n",
       "4                                         [sons, of]            0           1  \n",
       "5  [http, //www, dothebouncy, com/smf, some, sham...            0          13  \n",
       "6                                              [fun]            6           6  \n",
       "7                                      [soooo, high]            0           1  \n",
       "8                                    [both, of, you]            0           2  \n",
       "9                        [wow, just, became, cooler]            1           4  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add 2 new columns to our dataframe content listes of splitted text end selected text\n",
    "train_df[\"text_tokenize\"]=tweet_preprocessing(train_df.text.astype(str))\n",
    "train_df[\"selected_text_tokenize\"]=tweet_preprocessing(train_df.selected_text.astype(str))\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save the new dataframe in other file csv\n",
    "#train_df.to_csv(\"preprocessed_train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>selected_text_tokenize</th>\n",
       "      <th>first_index</th>\n",
       "      <th>last_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, have, responded, if, were, going]</td>\n",
       "      <td>[id, have, responded, if, were, going]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, will, miss, you, here, in, san, di...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, of]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[http, //www, dothebouncy, com/smf, some, sham...</td>\n",
       "      <td>[http, //www, dothebouncy, com/smf, some, sham...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "\n",
       "                                       selected_text sentiment  \\\n",
       "0                I`d have responded, if I were going   neutral   \n",
       "1                                           Sooo SAD  negative   \n",
       "2                                        bullying me  negative   \n",
       "3                                     leave me alone  negative   \n",
       "4                                      Sons of ****,  negative   \n",
       "5  http://www.dothebouncy.com/smf - some shameles...   neutral   \n",
       "\n",
       "                                       text_tokenize  \\\n",
       "0             [id, have, responded, if, were, going]   \n",
       "1  [sooo, sad, will, miss, you, here, in, san, di...   \n",
       "2                       [my, boss, is, bullying, me]   \n",
       "3                [what, interview, leave, me, alone]   \n",
       "4  [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "5  [http, //www, dothebouncy, com/smf, some, sham...   \n",
       "\n",
       "                              selected_text_tokenize  first_index  last_index  \n",
       "0             [id, have, responded, if, were, going]            0           4  \n",
       "1                                        [sooo, sad]            0           1  \n",
       "2                                     [bullying, me]            3           4  \n",
       "3                                 [leave, me, alone]            2           4  \n",
       "4                                         [sons, of]            0           1  \n",
       "5  [http, //www, dothebouncy, com/smf, some, sham...            0          13  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessed_df = pd.read_csv(\"preprocessed_train_data.csv\",keep_default_na=False)\n",
    "#del preprocessed_df['Unnamed: 0']\n",
    "preprocessed_df = train_df\n",
    "preprocessed_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>selected_text_tokenize</th>\n",
       "      <th>first_index</th>\n",
       "      <th>last_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, have, responded, if, were, going]</td>\n",
       "      <td>[id, have, responded, if, were, going]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, will, miss, you, here, in, san, di...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, of]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, we, could, come, see, on, denver, husba...</td>\n",
       "      <td>[lost]</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ive, wondered, about, rake, to, the, client, ...</td>\n",
       "      <td>[dont, force]</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, for, both, of, you, enjoy, the, br...</td>\n",
       "      <td>[yay, good, for, both, of, you]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0                 [id, have, responded, if, were, going]   \n",
       "1      [sooo, sad, will, miss, you, here, in, san, di...   \n",
       "2                           [my, boss, is, bullying, me]   \n",
       "3                    [what, interview, leave, me, alone]   \n",
       "4      [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "...                                                  ...   \n",
       "27476  [wish, we, could, come, see, on, denver, husba...   \n",
       "27477  [ive, wondered, about, rake, to, the, client, ...   \n",
       "27478  [yay, good, for, both, of, you, enjoy, the, br...   \n",
       "27479                          [but, it, was, worth, it]   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...   \n",
       "\n",
       "                                  selected_text_tokenize  first_index  \\\n",
       "0                 [id, have, responded, if, were, going]            0   \n",
       "1                                            [sooo, sad]            0   \n",
       "2                                         [bullying, me]            3   \n",
       "3                                     [leave, me, alone]            2   \n",
       "4                                             [sons, of]            0   \n",
       "...                                                  ...          ...   \n",
       "27476                                             [lost]            8   \n",
       "27477                                      [dont, force]           13   \n",
       "27478                    [yay, good, for, both, of, you]            0   \n",
       "27479                          [but, it, was, worth, it]            0   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...            0   \n",
       "\n",
       "       last_index  \n",
       "0               5  \n",
       "1               1  \n",
       "2               4  \n",
       "3               4  \n",
       "4               1  \n",
       "...           ...  \n",
       "27476           8  \n",
       "27477          14  \n",
       "27478           5  \n",
       "27479           1  \n",
       "27480           9  \n",
       "\n",
       "[27481 rows x 8 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "# if we want first index we choose True, and False for the latest index\n",
    "# we should use the next 2 lines one time (transform text to list)\n",
    "#preprocessed_df[\"text_tokenize\"] = preprocessed_df.text_tokenize.apply(lambda x: ast.literal_eval(x))\n",
    "#preprocessed_df[\"selected_text_tokenize\"] = preprocessed_df.selected_text_tokenize.apply(lambda x: ast.literal_eval(x))\n",
    "#preprocessed_df.head()\n",
    "\n",
    "def find_index (text_list,selectedText_list,i=True):  \n",
    "    #find first word in selected_text\n",
    "    try :\n",
    "        if i == True :\n",
    "            first_w = selectedText_list[0]\n",
    "            #print(first_w)\n",
    "            return (int(text_list.index(first_w))) \n",
    "            #find last word in selected_text\n",
    "        else:\n",
    "            last_w = selectedText_list[-1]\n",
    "            # look for first_w index in text list\n",
    "            return (int(text_list.index(last_w)))\n",
    "    except :\n",
    "        pass\n",
    "a = preprocessed_df.text_tokenize.loc[2]\n",
    "b = preprocessed_df.selected_text_tokenize.loc[2]  \n",
    "s = find_index (a,b,i=True)\n",
    "s\n",
    "\n",
    "preprocessed_df[\"first_index\"] = preprocessed_df.apply(lambda row : find_index(row.text_tokenize,row.selected_text_tokenize,True),axis=1)\n",
    "preprocessed_df[\"last_index\"] = preprocessed_df.apply(lambda row : find_index(row.text_tokenize,row.selected_text_tokenize,False),axis=1)\n",
    "#to convert float to int pandas\n",
    "pd.options.display.float_format = '{:,.0f}'.format\n",
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' wish we could come see u on Denver  husband lost his job and can`t afford it'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.text.iloc[27476]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of null values\n",
    "preprocessed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with any NaN and NaT values\n",
    "preprocessed_df = preprocessed_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID                    0\n",
       "text                      0\n",
       "selected_text             0\n",
       "sentiment                 0\n",
       "text_tokenize             0\n",
       "selected_text_tokenize    0\n",
       "first_index               0\n",
       "last_index                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>selected_text_tokenize</th>\n",
       "      <th>first_index</th>\n",
       "      <th>last_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, have, responded, if, were, going]</td>\n",
       "      <td>[id, have, responded, if, were, going]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, will, miss, you, here, in, san, di...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, of]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, we, could, come, see, on, denver, husba...</td>\n",
       "      <td>[lost]</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ive, wondered, about, rake, to, the, client, ...</td>\n",
       "      <td>[dont, force]</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, for, both, of, you, enjoy, the, br...</td>\n",
       "      <td>[yay, good, for, both, of, you]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26557 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0                 [id, have, responded, if, were, going]   \n",
       "1      [sooo, sad, will, miss, you, here, in, san, di...   \n",
       "2                           [my, boss, is, bullying, me]   \n",
       "3                    [what, interview, leave, me, alone]   \n",
       "4      [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "...                                                  ...   \n",
       "27476  [wish, we, could, come, see, on, denver, husba...   \n",
       "27477  [ive, wondered, about, rake, to, the, client, ...   \n",
       "27478  [yay, good, for, both, of, you, enjoy, the, br...   \n",
       "27479                          [but, it, was, worth, it]   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...   \n",
       "\n",
       "                                  selected_text_tokenize  first_index  \\\n",
       "0                 [id, have, responded, if, were, going]            0   \n",
       "1                                            [sooo, sad]            0   \n",
       "2                                         [bullying, me]            3   \n",
       "3                                     [leave, me, alone]            2   \n",
       "4                                             [sons, of]            0   \n",
       "...                                                  ...          ...   \n",
       "27476                                             [lost]            8   \n",
       "27477                                      [dont, force]           13   \n",
       "27478                    [yay, good, for, both, of, you]            0   \n",
       "27479                          [but, it, was, worth, it]            0   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...            0   \n",
       "\n",
       "       last_index  \n",
       "0               5  \n",
       "1               1  \n",
       "2               4  \n",
       "3               4  \n",
       "4               1  \n",
       "...           ...  \n",
       "27476           8  \n",
       "27477          14  \n",
       "27478           5  \n",
       "27479           1  \n",
       "27480           9  \n",
       "\n",
       "[26557 rows x 8 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   18,    27,    32,    39,    48,    64,   102,   149,   160,\n",
       "              196,\n",
       "            ...\n",
       "            27280, 27302, 27349, 27360, 27362, 27386, 27401, 27427, 27456,\n",
       "            27474],\n",
       "           dtype='int64', length=1234)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "preprocessed_df.index[preprocessed_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'onna'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.selected_text.iloc[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "preprocessed_df['first_index'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "######## tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>selected_text_tokenize</th>\n",
       "      <th>first_index</th>\n",
       "      <th>last_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>[id, have, responded, if, i, were, going]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "      <td>[bullying, me]</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "      <td>[leave, me, alone]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>[sons, of, why, couldnt, they, put, them, on, ...</td>\n",
       "      <td>[sons, of]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>[wish, we, could, come, see, u, on, denver, hu...</td>\n",
       "      <td>[d, lost]</td>\n",
       "      <td>nan</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>[ive, wondered, about, rake, to, the, client, ...</td>\n",
       "      <td>[dont, force]</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[yay, good, for, both, of, you, enjoy, the, br...</td>\n",
       "      <td>[yay, good, for, both, of, you]</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>[but, it, was, worth, it]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>[all, this, flirting, going, on, the, atg, smi...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27476                                             d lost  negative   \n",
       "27477                                      , don`t force  negative   \n",
       "27478                          Yay good for both of you.  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                           text_tokenize  \\\n",
       "0              [id, have, responded, if, i, were, going]   \n",
       "1      [sooo, sad, i, will, miss, you, here, in, san,...   \n",
       "2                           [my, boss, is, bullying, me]   \n",
       "3                    [what, interview, leave, me, alone]   \n",
       "4      [sons, of, why, couldnt, they, put, them, on, ...   \n",
       "...                                                  ...   \n",
       "27476  [wish, we, could, come, see, u, on, denver, hu...   \n",
       "27477  [ive, wondered, about, rake, to, the, client, ...   \n",
       "27478  [yay, good, for, both, of, you, enjoy, the, br...   \n",
       "27479                          [but, it, was, worth, it]   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...   \n",
       "\n",
       "                                  selected_text_tokenize  first_index  \\\n",
       "0              [id, have, responded, if, i, were, going]            0   \n",
       "1                                            [sooo, sad]            0   \n",
       "2                                         [bullying, me]            3   \n",
       "3                                     [leave, me, alone]            2   \n",
       "4                                             [sons, of]            0   \n",
       "...                                                  ...          ...   \n",
       "27476                                          [d, lost]          nan   \n",
       "27477                                      [dont, force]           13   \n",
       "27478                    [yay, good, for, both, of, you]            0   \n",
       "27479                          [but, it, was, worth, it]            0   \n",
       "27480  [all, this, flirting, going, on, the, atg, smi...            0   \n",
       "\n",
       "       last_index  \n",
       "0               6  \n",
       "1               1  \n",
       "2               4  \n",
       "3               4  \n",
       "4               1  \n",
       "...           ...  \n",
       "27476           9  \n",
       "27477          14  \n",
       "27478           5  \n",
       "27479           1  \n",
       "27480           9  \n",
       "\n",
       "[27481 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd \n",
    "import ast\n",
    "import tensorflow\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df['first_index'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df['last_index'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27278"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tokenize and make the index of words\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(preprocessed_df.text_tokenize)\n",
    "tokenized_text = tokenizer.texts_to_sequences(preprocessed_df.text_tokenize)\n",
    "tokenized_selected_text = tokenizer.texts_to_sequences(preprocessed_df.selected_text_tokenize)\n",
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index of word but\n",
    "tokenizer.word_index[\"but\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  292,    16, 10103, ...,     0,     0,     0],\n",
       "       [  408,   112,    56, ...,     0,     0,     0],\n",
       "       [    3,  1270,     7, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  222,    29,     9, ...,     0,     0,     0],\n",
       "       [   17,     6,    25, ...,     0,     0,     0],\n",
       "       [   26,    28,  6088, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after tokenzation we can prepare input of the module  \n",
    "pad_token_text = pad_sequences(tokenized_text,padding = \"post\")\n",
    "pad_token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed_df.DataFrame(pad_token_text).to_csv(\"pad_token_text.csv\",header=None,index=None)\n",
    "#preprocessed_df.to_csv(\"tokenized.csv\",index=None)\n",
    "#with open('tokenizer.pickle', 'wb') as handle:\n",
    "#    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "## and finally -----> the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.python.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_index</th>\n",
       "      <th>last_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_index  last_index\n",
       "0            0           5\n",
       "1            0           1\n",
       "2            3           4\n",
       "3            2           4\n",
       "4            0           1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = preprocessed_df[[\"first_index\",\"last_index\"]]\n",
    "targets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>291</td>\n",
       "      <td>16</td>\n",
       "      <td>9941</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>1425</td>\n",
       "      <td>2162</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1266</td>\n",
       "      <td>9</td>\n",
       "      <td>9942</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>1099</td>\n",
       "      <td>342</td>\n",
       "      <td>15</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2679</td>\n",
       "      <td>12</td>\n",
       "      <td>109</td>\n",
       "      <td>388</td>\n",
       "      <td>86</td>\n",
       "      <td>314</td>\n",
       "      <td>128</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>6750</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3    4    5    6   7     8     9   ...  23  24  25  26  \\\n",
       "0   291    16  9941    68    1  119   45   0     0     0  ...   0   0   0   0   \n",
       "1   410   116     1    59   90    7   87  10  1425  2162  ...   0   0   0   0   \n",
       "2     5  1266     9  9942   15    0    0   0     0     0  ...   0   0   0   0   \n",
       "3    57  1099   342    15  490    0    0   0     0     0  ...   0   0   0   0   \n",
       "4  2679    12   109   388   86  314  128  14     3  6750  ...   0   0   0   0   \n",
       "\n",
       "   27  28  29  30  31  32  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = pd.read_csv(\"pad_token_text.csv\",header= None)\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after preparing input and output we can split data for testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(pad_token_text, targets.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_model(vocab_size):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, 128, input_length=31),\n",
    "        Bidirectional(GRU(128, return_sequences=True, dropout=0.8, recurrent_dropout=0.8)),\n",
    "        Bidirectional(GRU(128,return_sequences=True, dropout=0.8, recurrent_dropout=0.8)),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='elu',kernel_regularizer=l1_l2()),\n",
    "        Dropout(0.8),\n",
    "        Dense(2, activation='elu'),\n",
    "        Flatten(),\n",
    "        Dense(2, activation='elu')\n",
    "\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21245, 31)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21245, 2)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 31, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 31, 256)           197376    \n",
      "_________________________________________________________________\n",
      "bidirectional_18 (Bidirectio (None, 31, 256)           295680    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 31, 64)            16448     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 31, 64)            0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 31, 2)             130       \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 62)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 126       \n",
      "=================================================================\n",
      "Total params: 3,070,784\n",
      "Trainable params: 3,070,272\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab = 20000\n",
    "model = first_model(vocab)\n",
    "es = EarlyStopping(patience=5)\n",
    "#tweet_sentiment.hdf5\n",
    "mcp_save = ModelCheckpoint('model.hdf5', save_best_only=True, monitor='val_mse')\n",
    "model.compile(loss=\"mse\",optimizer=\"adam\",metrics=['mse',\"mae\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16996 samples, validate on 4249 samples\n",
      "Epoch 1/100\n",
      "16996/16996 [==============================] - 183s 11ms/step - loss: 44.5785 - mean_squared_error: 33.7168 - mean_absolute_error: 4.1778 - val_loss: 32.3094 - val_mean_squared_error: 22.9963 - val_mean_absolute_error: 3.2670\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 992, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 838, in format\n",
      "    return fmt.format(record)\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 575, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"c:\\program files\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\program files\\python36\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\program files\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 362, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 265, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-129-ebebbb848198>\", line 2, in <module>\n",
      "    history = model.fit(x=x_train, y=y_train, batch_size = 32, epochs=100, validation_split = 0.2,callbacks=[es,mcp_save])\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 1216, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_arrays.py\", line 269, in fit_loop\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\callbacks.py\", line 95, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\callbacks.py\", line 457, in on_epoch_end\n",
      "    'skipping.', self.monitor, RuntimeWarning)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\platform\\tf_logging.py\", line 126, in warning\n",
      "    _get_logger().warning(msg, *args, **kwargs)\n",
      "Message: 'Can save best model only with %s available, skipping.'\n",
      "Arguments: ('val_mse', <class 'RuntimeWarning'>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16996/16996 [==============================] - 179s 11ms/step - loss: 29.2215 - mean_squared_error: 21.4340 - mean_absolute_error: 3.4252 - val_loss: 26.6009 - val_mean_squared_error: 20.3107 - val_mean_absolute_error: 3.4324\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 992, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 838, in format\n",
      "    return fmt.format(record)\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 575, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"c:\\program files\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\program files\\python36\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\program files\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 362, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 265, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-129-ebebbb848198>\", line 2, in <module>\n",
      "    history = model.fit(x=x_train, y=y_train, batch_size = 32, epochs=100, validation_split = 0.2,callbacks=[es,mcp_save])\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 1216, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_arrays.py\", line 269, in fit_loop\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\callbacks.py\", line 95, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\callbacks.py\", line 457, in on_epoch_end\n",
      "    'skipping.', self.monitor, RuntimeWarning)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\platform\\tf_logging.py\", line 126, in warning\n",
      "    _get_logger().warning(msg, *args, **kwargs)\n",
      "Message: 'Can save best model only with %s available, skipping.'\n",
      "Arguments: ('val_mse', <class 'RuntimeWarning'>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16996/16996 [==============================] - 179s 11ms/step - loss: 25.1886 - mean_squared_error: 20.2355 - mean_absolute_error: 3.3230 - val_loss: 23.4701 - val_mean_squared_error: 19.7777 - val_mean_absolute_error: 3.2535\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 992, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 838, in format\n",
      "    return fmt.format(record)\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 575, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"c:\\program files\\python36\\lib\\logging\\__init__.py\", line 338, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"c:\\program files\\python36\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\program files\\python36\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\program files\\python36\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\program files\\python36\\lib\\asyncio\\events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 362, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 265, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n",
      "    return f(*args, **kw)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"c:\\program files\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-129-ebebbb848198>\", line 2, in <module>\n",
      "    history = model.fit(x=x_train, y=y_train, batch_size = 32, epochs=100, validation_split = 0.2,callbacks=[es,mcp_save])\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\", line 1216, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_arrays.py\", line 269, in fit_loop\n",
      "    callbacks.on_epoch_end(epoch, epoch_logs)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\callbacks.py\", line 95, in on_epoch_end\n",
      "    callback.on_epoch_end(epoch, logs)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\callbacks.py\", line 457, in on_epoch_end\n",
      "    'skipping.', self.monitor, RuntimeWarning)\n",
      "  File \"C:\\Users\\Achraf\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\platform\\tf_logging.py\", line 126, in warning\n",
      "    _get_logger().warning(msg, *args, **kwargs)\n",
      "Message: 'Can save best model only with %s available, skipping.'\n",
      "Arguments: ('val_mse', <class 'RuntimeWarning'>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8096/16996 [=============>................] - ETA: 1:33 - loss: 23.2010 - mean_squared_error: 19.9638 - mean_absolute_error: 3.2896"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-ebebbb848198>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# epochs 100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1214\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    243\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2822\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2823\u001b[0m     updated = session.run(\n\u001b[1;32m-> 2824\u001b[1;33m         fetches=fetches, feed_dict=feed_dict, **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2825\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# epochs 100   \n",
    "history = model.fit(x=x_train, y=y_train, batch_size = 32, epochs=100, validation_split = 0.2,callbacks=[es,mcp_save])\n",
    "model.save('model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## prepartion of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[last, session, of, the, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[shanghai, is, also, really, exciting, precise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[recession, hit, veronique, branquinho, she, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>[happy, bday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "\n",
       "                                       text_tokenize  \n",
       "0                      [last, session, of, the, day]  \n",
       "1  [shanghai, is, also, really, exciting, precise...  \n",
       "2  [recession, hit, veronique, branquinho, she, h...  \n",
       "3                                      [happy, bday]  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add 2 new columns to our dataframe content listes of splitted text end selected text\n",
    "test_df[\"text_tokenize\"]=tweet_preprocessing(test_df.text.astype(str))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "## tokenize and make the index of words\n",
    "tokenizer = Tokenizer(num_words=20000,oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(test_df.text_tokenize)\n",
    "test_tokenized_text = tokenizer.texts_to_sequences(test_df.text_tokenize)\n",
    "test_pad_token_text = pad_sequences(test_tokenized_text,maxlen=33, padding = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.python.keras.regularizers import l2, l1, l1_l2\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score\n",
    "################################################################################################################\n",
    "model = first_model(22000)\n",
    "model.load_weights(\"model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       ...,\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_results = model.predict(test_pad_token_text)\n",
    "predict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       ...,\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_results = np.round(predict_results)\n",
    "predict_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[last, session, of, the, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[shanghai, is, also, really, exciting, precise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[recession, hit, veronique, branquinho, she, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>[happy, bday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "\n",
       "                                       text_tokenize  \n",
       "0                      [last, session, of, the, day]  \n",
       "1  [shanghai, is, also, really, exciting, precise...  \n",
       "2  [recession, hit, veronique, branquinho, she, h...  \n",
       "3                                      [happy, bday]  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"final_split\"] = test_df.text.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selecter(split_text,indices):\n",
    "    try:\n",
    "        return \" \".join(split_text[int(indices[0][0]):int(indices[0][1])])\n",
    "    except:\n",
    "        return \" \".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"selected_text\"] = test_df.apply(lambda x: selecter(x.text_tokenize,predict_results), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>final_split</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[last, session, of, the, day]</td>\n",
       "      <td>[Last, session, of, the, day, http://twitpic.c...</td>\n",
       "      <td>last session of the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[shanghai, is, also, really, exciting, precise...</td>\n",
       "      <td>[Shanghai, is, also, really, exciting, (precis...</td>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[recession, hit, veronique, branquinho, she, h...</td>\n",
       "      <td>[Recession, hit, Veronique, Branquinho,, she, ...</td>\n",
       "      <td>recession hit veronique branquinho she has to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "      <td>[happy, bday]</td>\n",
       "      <td>[happy, bday!]</td>\n",
       "      <td>happy bday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "      <td>[]</td>\n",
       "      <td>[http://twitpic.com/4w75p, -, I, like, it!!]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>726e501993</td>\n",
       "      <td>that`s great!! weee!! visitors!</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thats, great, weee, visitors]</td>\n",
       "      <td>[that`s, great!!, weee!!, visitors!]</td>\n",
       "      <td>thats great weee visitors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>261932614e</td>\n",
       "      <td>I THINK EVERYONE HATES ME ON HERE   lol</td>\n",
       "      <td>negative</td>\n",
       "      <td>[i, think, everyone, hates, me, on, here, lol]</td>\n",
       "      <td>[I, THINK, EVERYONE, HATES, ME, ON, HERE, lol]</td>\n",
       "      <td>i think everyone hates me on here lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>afa11da83f</td>\n",
       "      <td>soooooo wish i could, but im in school and my...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[soooooo, wish, i, could, but, im, in, school,...</td>\n",
       "      <td>[soooooo, wish, i, could,, but, im, in, school...</td>\n",
       "      <td>soooooo wish i could but im in school and mysp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e64208b4ef</td>\n",
       "      <td>and within a short time of the last clue all ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[and, within, a, short, time, of, the, last, c...</td>\n",
       "      <td>[and, within, a, short, time, of, the, last, c...</td>\n",
       "      <td>and within a short time of the last clue all o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37bcad24ca</td>\n",
       "      <td>What did you get?  My day is alright.. haven`...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[what, did, you, get, my, day, is, alright, ha...</td>\n",
       "      <td>[What, did, you, get?, My, day, is, alright..,...</td>\n",
       "      <td>what did you get my day is alright havent done...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive   \n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative   \n",
       "3  01082688c6                                        happy bday!  positive   \n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive   \n",
       "5  726e501993                    that`s great!! weee!! visitors!  positive   \n",
       "6  261932614e            I THINK EVERYONE HATES ME ON HERE   lol  negative   \n",
       "7  afa11da83f   soooooo wish i could, but im in school and my...  negative   \n",
       "8  e64208b4ef   and within a short time of the last clue all ...   neutral   \n",
       "9  37bcad24ca   What did you get?  My day is alright.. haven`...   neutral   \n",
       "\n",
       "                                       text_tokenize  \\\n",
       "0                      [last, session, of, the, day]   \n",
       "1  [shanghai, is, also, really, exciting, precise...   \n",
       "2  [recession, hit, veronique, branquinho, she, h...   \n",
       "3                                      [happy, bday]   \n",
       "4                                                 []   \n",
       "5                     [thats, great, weee, visitors]   \n",
       "6     [i, think, everyone, hates, me, on, here, lol]   \n",
       "7  [soooooo, wish, i, could, but, im, in, school,...   \n",
       "8  [and, within, a, short, time, of, the, last, c...   \n",
       "9  [what, did, you, get, my, day, is, alright, ha...   \n",
       "\n",
       "                                         final_split  \\\n",
       "0  [Last, session, of, the, day, http://twitpic.c...   \n",
       "1  [Shanghai, is, also, really, exciting, (precis...   \n",
       "2  [Recession, hit, Veronique, Branquinho,, she, ...   \n",
       "3                                     [happy, bday!]   \n",
       "4       [http://twitpic.com/4w75p, -, I, like, it!!]   \n",
       "5               [that`s, great!!, weee!!, visitors!]   \n",
       "6     [I, THINK, EVERYONE, HATES, ME, ON, HERE, lol]   \n",
       "7  [soooooo, wish, i, could,, but, im, in, school...   \n",
       "8  [and, within, a, short, time, of, the, last, c...   \n",
       "9  [What, did, you, get?, My, day, is, alright..,...   \n",
       "\n",
       "                                       selected_text  \n",
       "0                            last session of the day  \n",
       "1  shanghai is also really exciting precisely sky...  \n",
       "2  recession hit veronique branquinho she has to ...  \n",
       "3                                         happy bday  \n",
       "4                                                     \n",
       "5                          thats great weee visitors  \n",
       "6              i think everyone hates me on here lol  \n",
       "7  soooooo wish i could but im in school and mysp...  \n",
       "8  and within a short time of the last clue all o...  \n",
       "9  what did you get my day is alright havent done...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Baseline(vocab_size):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, 128, input_length=33),\n",
    "        Bidirectional(GRU(128, return_sequences=True, dropout=0.8, recurrent_dropout=0.8)),\n",
    "        Bidirectional(GRU(128,return_sequences=True, dropout=0.8, recurrent_dropout=0.8)),\n",
    "        BatchNormalization(),\n",
    "        Dense(64, activation='elu',kernel_regularizer=l1_l2()),\n",
    "        Dropout(0.8),\n",
    "        Dense(2, activation='elu'),\n",
    "        Flatten(),\n",
    "        Dense(2, activation='elu')\n",
    "\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes must be equal rank, but are 1 and 2 for 'Assign_51' (op: 'Assign') with input shapes: [384], [2,384].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1566\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1567\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Shapes must be equal rank, but are 1 and 2 for 'Assign_51' (op: 'Assign') with input shapes: [384], [2,384].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-8a50abad7871>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:/Users/Achraf/Desktop/test/11/Tweet-Sentiment-Extraction-master/tweet_sentiment_extraction/Modeling/tweet_sentiment.hdf5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m         \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    717\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[0;32m    718\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m   \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2700\u001b[0m           assign_placeholder = array_ops.placeholder(tf_dtype,\n\u001b[0;32m   2701\u001b[0m                                                      shape=value.shape)\n\u001b[1;32m-> 2702\u001b[1;33m           \u001b[0massign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2703\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2704\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking)\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \"\"\"\n\u001b[1;32m--> 615\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m    281\u001b[0m     return gen_state_ops.assign(\n\u001b[0;32m    282\u001b[0m         \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    284\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m     61\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m     62\u001b[0m         \u001b[1;34m\"Assign\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3392\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m       \u001b[1;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1734\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1735\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1568\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes must be equal rank, but are 1 and 2 for 'Assign_51' (op: 'Assign') with input shapes: [384], [2,384]."
     ]
    }
   ],
   "source": [
    "model = Baseline(20000)\n",
    "model.load_weights(\"C:/Users/Achraf/Desktop/test/11/Tweet-Sentiment-Extraction-master/tweet_sentiment_extraction/Modeling/tweet_sentiment.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       ...,\n",
       "       [nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(test_pad_token_text)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
